好的！下面给你一段“工业级”风格的 Go 对象存储微服务示例代码：
特点：S3/MinIO 兼容、流式上传下载、自动多段上传、上下文取消、结构化日志、Prometheus 指标、健康检查、优雅退出、速率限制与超时、可通过环境变量配置。代码偏**工程化**，可直接改造成生产服务。

---

### `go.mod`

```go
module corp/objectstore

go 1.22

require (
	github.com/aws/aws-sdk-go-v2 v1.32.0
	github.com/aws/aws-sdk-go-v2/config v1.28.0
	github.com/aws/aws-sdk-go-v2/feature/s3/manager v1.17.0
	github.com/aws/aws-sdk-go-v2/service/s3 v1.64.0
	github.com/go-chi/chi/v5 v5.1.0
	github.com/prometheus/client_golang v1.20.5
	github.com/rs/zerolog v1.33.0
	golang.org/x/time v0.7.0
)
```

---

### `main.go`

```go
package main

import (
	"context"
	"crypto/md5"
	"encoding/base64"
	"errors"
	"fmt"
	"io"
	"log"
	"net"
	"net/http"
	_ "net/http/pprof"
	"os"
	"os/signal"
	"strconv"
	"strings"
	"syscall"
	"time"

	"github.com/aws/aws-sdk-go-v2/aws"
	"github.com/aws/aws-sdk-go-v2/config"
	"github.com/aws/aws-sdk-go-v2/feature/s3/manager"
	"github.com/aws/aws-sdk-go-v2/service/s3"
	s3types "github.com/aws/aws-sdk-go-v2/service/s3/types"
	"github.com/go-chi/chi/v5"
	"github.com/go-chi/chi/v5/middleware"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/client_golang/prometheus/promhttp"
	"github.com/rs/zerolog"
	"github.com/rs/zerolog/hlog"
	"golang.org/x/time/rate"
)

type Config struct {
	// HTTP
	Addr           string        // 监听地址
	RequestTimeout time.Duration // 每个请求的超时

	// Rate limit
	GlobalQPS float64
	Burst     int

	// S3/MinIO
	Region          string
	Endpoint        string // 例如 http://127.0.0.1:9000 （MinIO）或留空使用 AWS
	AccessKeyID     string
	SecretAccessKey string
	BucketFallback  string // 当未在路由中指定时的默认桶
	UsePathStyle    bool   // MinIO 通常需要 true

	// Upload
	MultipartThreshold int64 // 超过该阈值启用多段上传
	PartSize           int64 // 多段上传分片大小
	MaxConcurrency     int   // 多段上传并发
}

func loadConfig() Config {
	getEnv := func(key, def string) string {
		if v := os.Getenv(key); v != "" {
			return v
		}
		return def
	}
	getEnvInt64 := func(key string, def int64) int64 {
		if v := os.Getenv(key); v != "" {
			if x, err := strconv.ParseInt(v, 10, 64); err == nil {
				return x
			}
		}
		return def
	}
	getEnvFloat := func(key string, def float64) float64 {
		if v := os.Getenv(key); v != "" {
			if x, err := strconv.ParseFloat(v, 64); err == nil {
				return x
			}
		}
		return def
	}
	getEnvBool := func(key string, def bool) bool {
		if v := os.Getenv(key); v != "" {
			switch strings.ToLower(v) {
			case "1", "true", "t", "yes", "y":
				return true
			case "0", "false", "f", "no", "n":
				return false
			}
		}
		return def
	}
	getEnvDuration := func(key string, def time.Duration) time.Duration {
		if v := os.Getenv(key); v != "" {
			if d, err := time.ParseDuration(v); err == nil {
				return d
			}
		}
		return def
	}

	return Config{
		Addr:               getEnv("ADDR", ":8080"),
		RequestTimeout:     getEnvDuration("REQUEST_TIMEOUT", 30*time.Second),
		GlobalQPS:          getEnvFloat("GLOBAL_QPS", 200), // 全局 200 QPS
		Burst:              int(getEnvInt64("GLOBAL_BURST", 400)),
		Region:             getEnv("S3_REGION", "us-east-1"),
		Endpoint:           getEnv("S3_ENDPOINT", ""),
		AccessKeyID:        getEnv("S3_ACCESS_KEY_ID", ""),
		SecretAccessKey:    getEnv("S3_SECRET_ACCESS_KEY", ""),
		BucketFallback:     getEnv("S3_BUCKET", ""),
		UsePathStyle:       getEnvBool("S3_USE_PATH_STYLE", true),
		MultipartThreshold: getEnvInt64("S3_MULTIPART_THRESHOLD", 64<<20), // 64 MiB
		PartSize:           getEnvInt64("S3_PART_SIZE", 16<<20),           // 16 MiB
		MaxConcurrency:     int(getEnvInt64("S3_MAX_CONCURRENCY", 4)),
	}
}

type Server struct {
	cfg       Config
	log       zerolog.Logger
	s3        *s3.Client
	uploader  *manager.Uploader
	limiter   *rate.Limiter
	registry  *prometheus.Registry
	metricUp  *prometheus.CounterVec
	metricGet *prometheus.CounterVec
	metricDur *prometheus.HistogramVec
}

func newServer(ctx context.Context, cfg Config) (*Server, error) {
	// 日志
	zlog := zerolog.New(os.Stdout).With().
		Timestamp().
		Str("svc", "objectstore").
		Logger()

	// Prometheus
	reg := prometheus.NewRegistry()
	metricUp := prometheus.NewCounterVec(prometheus.CounterOpts{
		Namespace: "objstore", Name: "upload_total", Help: "upload counter",
	}, []string{"status"})
	metricGet := prometheus.NewCounterVec(prometheus.CounterOpts{
		Namespace: "objstore", Name: "download_total", Help: "download counter",
	}, []string{"status"})
	metricDur := prometheus.NewHistogramVec(prometheus.HistogramOpts{
		Namespace: "objstore", Name: "handler_duration_seconds", Help: "handler latency",
		Buckets: prometheus.DefBuckets,
	}, []string{"route", "method", "status"})
	reg.MustRegister(metricUp, metricGet, metricDur)

	// AWS/S3 配置
	var loadOpts []func(*config.LoadOptions) error
	if cfg.AccessKeyID != "" && cfg.SecretAccessKey != "" {
		loadOpts = append(loadOpts, config.WithCredentialsProvider(
			aws.CredentialsProviderFunc(func(context.Context) (aws.Credentials, error) {
				return aws.Credentials{
					AccessKeyID: cfg.AccessKeyID, SecretAccessKey: cfg.SecretAccessKey, Source: "env",
				}, nil
			}),
		))
	}
	if cfg.Region != "" {
		loadOpts = append(loadOpts, config.WithRegion(cfg.Region))
	}

	// 自定义 endpoint（MinIO）
	var endpointResolver aws.EndpointResolverWithOptions
	if cfg.Endpoint != "" {
		endpointResolver = aws.EndpointResolverWithOptionsFunc(func(service, region string, _ ...interface{}) (aws.Endpoint, error) {
			if service == s3.ServiceID {
				return aws.Endpoint{
					URL:               cfg.Endpoint,
					HostnameImmutable: true,
				}, nil
			}
			return aws.Endpoint{}, &aws.EndpointNotFoundError{}
		})
		loadOpts = append(loadOpts, config.WithEndpointResolverWithOptions(endpointResolver))
	}

	awsCfg, err := config.LoadDefaultConfig(ctx, loadOpts...)
	if err != nil {
		return nil, fmt.Errorf("load aws cfg: %w", err)
	}

	s3cli := s3.NewFromConfig(awsCfg, func(o *s3.Options) {
		o.UsePathStyle = cfg.UsePathStyle
	})
	up := manager.NewUploader(s3cli, func(u *manager.Uploader) {
		u.Concurrency = cfg.MaxConcurrency
		u.PartSize = cfg.PartSize
	})

	return &Server{
		cfg:       cfg,
		log:       zlog,
		s3:        s3cli,
		uploader:  up,
		limiter:   rate.NewLimiter(rate.Limit(cfg.GlobalQPS), cfg.Burst),
		registry:  reg,
		metricUp:  metricUp,
		metricGet: metricGet,
		metricDur: metricDur,
	}, nil
}

func (s *Server) routes() http.Handler {
	r := chi.NewRouter()

	// 基础中间件
	r.Use(middleware.RealIP)
	r.Use(middleware.Recoverer)
	r.Use(middleware.RequestID)
	r.Use(middleware.Timeout(s.cfg.RequestTimeout))

	// 结构化日志
	r.Use(hlog.NewHandler(s.log))
	r.Use(hlog.AccessHandler(func(r *http.Request, status, size int, dur time.Duration) {
		hlog.FromRequest(r).Info().
			Str("method", r.Method).
			Stringer("url", r.URL).
			Int("status", status).
			Int("size", size).
			Dur("dur", dur).
			Msg("request")
	}))

	// 全局速率限制
	r.Use(func(next http.Handler) http.Handler {
		return http.HandlerFunc(func(w http.ResponseWriter, req *http.Request) {
			if !s.limiter.Allow() {
				http.Error(w, "rate limit", http.StatusTooManyRequests)
				return
			}
			next.ServeHTTP(w, req)
		})
	})

	// 健康 & 监控
	r.Get("/livez", func(w http.ResponseWriter, _ *http.Request) { w.WriteHeader(http.StatusOK) })
	r.Get("/readyz", func(w http.ResponseWriter, _ *http.Request) { w.WriteHeader(http.StatusOK) })
	r.Mount("/metrics", promhttp.HandlerFor(s.registry, promhttp.HandlerOpts{}))

	// pprof（/debug/pprof/）
	r.Mount("/debug", http.DefaultServeMux)

	// API
	r.Route("/v1", func(r chi.Router) {
		r.Put("/buckets/{bucket}", s.handleCreateBucket)
		r.Put("/objects/{bucket}/*", s.handlePutObject)
		r.Get("/objects/{bucket}/*", s.handleGetObject)
		r.Head("/objects/{bucket}/*", s.handleHeadObject)
		r.Delete("/objects/{bucket}/*", s.handleDeleteObject)
	})

	return s.instrument(r)
}

// 指标封装
func (s *Server) instrument(next http.Handler) http.Handler {
	return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		ww := middleware.NewWrapResponseWriter(w, r.ProtoMajor)
		start := time.Now()
		next.ServeHTTP(ww, r)
		route := chi.RouteContext(r.Context()).RoutePattern()
		if route == "" {
			route = "unknown"
		}
		s.metricDur.WithLabelValues(route, r.Method, strconv.Itoa(ww.Status())).Observe(time.Since(start).Seconds())
	})
}

func (s *Server) handleCreateBucket(w http.ResponseWriter, r *http.Request) {
	ctx := r.Context()
	bucket := chi.URLParam(r, "bucket")
	if bucket == "" {
		http.Error(w, "bucket required", http.StatusBadRequest)
		return
	}
	_, err := s.s3.CreateBucket(ctx, &s3.CreateBucketInput{Bucket: aws.String(bucket)})
	if err != nil {
		var ae *s3types.BucketAlreadyOwnedByYou
		if errors.As(err, &ae) {
			w.WriteHeader(http.StatusOK)
			_, _ = w.Write([]byte("ok"))
			return
		}
		http.Error(w, err.Error(), http.StatusBadRequest)
		return
	}
	w.WriteHeader(http.StatusCreated)
	_, _ = w.Write([]byte("created"))
}

func (s *Server) handlePutObject(w http.ResponseWriter, r *http.Request) {
	ctx := r.Context()
	bucket := chi.URLParam(r, "bucket")
	key := strings.TrimPrefix(chi.URLParam(r, "*"), "/")
	if bucket == "" {
		bucket = s.cfg.BucketFallback
	}
	if bucket == "" || key == "" {
		http.Error(w, "bucket/key required", http.StatusBadRequest)
		return
	}

	// 可选：客户端提供 MD5，用于单段上传校验
	clientMD5B64 := r.Header.Get("X-Checksum-MD5")

	// SSE-KMS 可选
	sseKMS := r.Header.Get("X-SSE-KMS-KeyId")

	// 根据 Content-Length 判定是否使用多段上传
	var contentLen int64 = -1
	if cl := r.Header.Get("Content-Length"); cl != "" {
		if v, err := strconv.ParseInt(cl, 10, 64); err == nil {
			contentLen = v
		}
	}

	// 小文件：单段上传，支持 MD5 校验（S3 ETag 即 MD5，仅限单段）
	if contentLen >= 0 && contentLen <= s.cfg.MultipartThreshold {
		hasher := md5.New()
		body := io.TeeReader(r.Body, hasher)
		putIn := &s3.PutObjectInput{
			Bucket: aws.String(bucket),
			Key:    aws.String(key),
			Body:   io.NopCloser(body),
		}
		if sseKMS != "" {
			putIn.ServerSideEncryption = s3types.ServerSideEncryptionAwsKms
			putIn.SSEKMSKeyId = aws.String(sseKMS)
		}
		_, err := s.s3.PutObject(ctx, putIn)
		if err != nil {
			s.metricUp.WithLabelValues("error").Inc()
			http.Error(w, err.Error(), http.StatusBadRequest)
			return
		}
		if clientMD5B64 != "" {
			calced := base64.StdEncoding.EncodeToString(hasher.Sum(nil))
			if calced != clientMD5B64 {
				s.metricUp.WithLabelValues("md5_mismatch").Inc()
				http.Error(w, "md5 mismatch", http.StatusUnprocessableEntity)
				return
			}
		}
		s.metricUp.WithLabelValues("ok").Inc()
		w.WriteHeader(http.StatusCreated)
		_, _ = w.Write([]byte("uploaded: single-part"))
		return
	}

	// 大文件：多段上传（manager.Uploader 自动分片并发）
	upIn := &manager.UploadInput{
		Bucket: aws.String(bucket),
		Key:    aws.String(key),
		Body:   r.Body, // 流式直传
	}
	if sseKMS != "" {
		upIn.ServerSideEncryption = s3types.ServerSideEncryptionAwsKms
		upIn.SSEKMSKeyId = aws.String(sseKMS)
	}
	_, err := s.uploader.Upload(ctx, upIn)
	if err != nil {
		s.metricUp.WithLabelValues("error").Inc()
		http.Error(w, err.Error(), http.StatusBadRequest)
		return
	}
	s.metricUp.WithLabelValues("ok").Inc()
	w.WriteHeader(http.StatusCreated)
	_, _ = w.Write([]byte("uploaded: multipart"))
}

func (s *Server) handleGetObject(w http.ResponseWriter, r *http.Request) {
	ctx := r.Context()
	bucket := chi.URLParam(r, "bucket")
	key := strings.TrimPrefix(chi.URLParam(r, "*"), "/")
	if bucket == "" {
		bucket = s.cfg.BucketFallback
	}
	if bucket == "" || key == "" {
		http.Error(w, "bucket/key required", http.StatusBadRequest)
		return
	}

	// 支持 Range
	var rangeHeader *string
	if v := r.Header.Get("Range"); v != "" {
		rangeHeader = aws.String(v)
	}
	out, err := s.s3.GetObject(ctx, &s3.GetObjectInput{
		Bucket: aws.String(bucket),
		Key:    aws.String(key),
		Range:  rangeHeader,
	})
	if err != nil {
		s.metricGet.WithLabelValues("error").Inc()
		var nsk *s3types.NoSuchKey
		if errors.As(err, &nsk) {
			http.Error(w, "not found", http.StatusNotFound)
			return
		}
		http.Error(w, err.Error(), http.StatusBadRequest)
		return
	}
	defer out.Body.Close()

	// 透传部分元数据
	if out.ContentLength != nil && *out.ContentLength >= 0 {
		w.Header().Set("Content-Length", fmt.Sprintf("%d", *out.ContentLength))
	}
	if out.ContentType != nil {
		w.Header().Set("Content-Type", *out.ContentType)
	}
	if out.ETag != nil {
		w.Header().Set("ETag", *out.ETag)
	}
	if out.ContentRange != nil {
		w.Header().Set("Content-Range", *out.ContentRange)
		w.WriteHeader(http.StatusPartialContent)
	}

	if _, err := io.Copy(w, out.Body); err != nil {
		// 写出错误通常是客户端中断
		s.metricGet.WithLabelValues("client_abort").Inc()
		return
	}
	s.metricGet.WithLabelValues("ok").Inc()
}

func (s *Server) handleHeadObject(w http.ResponseWriter, r *http.Request) {
	ctx := r.Context()
	bucket := chi.URLParam(r, "bucket")
	key := strings.TrimPrefix(chi.URLParam(r, "*"), "/")
	if bucket == "" {
		bucket = s.cfg.BucketFallback
	}
	if bucket == "" || key == "" {
		http.Error(w, "bucket/key required", http.StatusBadRequest)
		return
	}
	out, err := s.s3.HeadObject(ctx, &s3.HeadObjectInput{
		Bucket: aws.String(bucket),
		Key:    aws.String(key),
	})
	if err != nil {
		var nsk *s3types.NotFound
		if errors.As(err, &nsk) {
			http.Error(w, "not found", http.StatusNotFound)
			return
		}
		http.Error(w, err.Error(), http.StatusBadRequest)
		return
	}
	if out.ContentLength != nil {
		w.Header().Set("Content-Length", fmt.Sprintf("%d", *out.ContentLength))
	}
	if out.ContentType != nil {
		w.Header().Set("Content-Type", *out.ContentType)
	}
	if out.ETag != nil {
		w.Header().Set("ETag", *out.ETag)
	}
	w.WriteHeader(http.StatusOK)
}

func (s *Server) handleDeleteObject(w http.ResponseWriter, r *http.Request) {
	ctx := r.Context()
	bucket := chi.URLParam(r, "bucket")
	key := strings.TrimPrefix(chi.URLParam(r, "*"), "/")
	if bucket == "" {
		bucket = s.cfg.BucketFallback
	}
	if bucket == "" || key == "" {
		http.Error(w, "bucket/key required", http.StatusBadRequest)
		return
	}
	_, err := s.s3.DeleteObject(ctx, &s3.DeleteObjectInput{
		Bucket: aws.String(bucket),
		Key:    aws.String(key),
	})
	if err != nil {
		http.Error(w, err.Error(), http.StatusBadRequest)
		return
	}
	w.WriteHeader(http.StatusNoContent)
}

func main() {
	cfg := loadConfig()

	ctx, cancel := signal.NotifyContext(context.Background(), syscall.SIGINT, syscall.SIGTERM)
	defer cancel()

	srv, err := newServer(ctx, cfg)
	if err != nil {
		log.Fatal(err)
	}

	handler := srv.routes()
	httpSrv := &http.Server{
		Addr:              cfg.Addr,
		Handler:           handler,
		ReadHeaderTimeout: 10 * time.Second,
	}

	ln, err := net.Listen("tcp", cfg.Addr)
	if err != nil {
		log.Fatal(err)
	}

	go func() {
		srv.log.Info().Str("addr", cfg.Addr).Msg("server starting")
		if err := httpSrv.Serve(ln); err != nil && !errors.Is(err, http.ErrServerClosed) {
			srv.log.Error().Err(err).Msg("server error")
			cancel()
		}
	}()

	<-ctx.Done()
	shutdownCtx, cancel2 := context.WithTimeout(context.Background(), 10*time.Second)
	defer cancel2()
	_ = httpSrv.Shutdown(shutdownCtx)
	srv.log.Info().Msg("server stopped")
}
```

---

### 运行与配置

```bash
# 以 MinIO 为例
export ADDR=":8080"
export REQUEST_TIMEOUT="30s"
export GLOBAL_QPS=200
export GLOBAL_BURST=400

export S3_ENDPOINT="http://127.0.0.1:9000"
export S3_REGION="us-east-1"
export S3_ACCESS_KEY_ID="minioadmin"
export S3_SECRET_ACCESS_KEY="minioadmin"
export S3_USE_PATH_STYLE=true
export S3_BUCKET="demo"

export S3_MULTIPART_THRESHOLD=$((64*1024*1024))
export S3_PART_SIZE=$((16*1024*1024))
export S3_MAX_CONCURRENCY=4

go mod tidy
go run .
```

基本用法（假设默认桶 `demo` 存在）：

```bash
# 创建桶
curl -X PUT localhost:8080/v1/buckets/demo

# 上传（小文件单段上载，支持MD5校验）
MD5=$(openssl md5 -binary my.txt | base64)
curl -X PUT --data-binary @my.txt \
  -H "X-Checksum-MD5: ${MD5}" \
  localhost:8080/v1/objects/demo/path/to/my.txt

# 上传（大文件自动多段）
curl -X PUT --data-binary @large.bin \
  localhost:8080/v1/objects/demo/big/large.bin

# 下载（支持 Range）
curl -v -H "Range: bytes=0-1023" \
  localhost:8080/v1/objects/demo/big/large.bin -o part0

# 元信息
curl -I localhost:8080/v1/objects/demo/path/to/my.txt

# 删除
curl -X DELETE localhost:8080/v1/objects/demo/path/to/my.txt

# 健康/监控
curl localhost:8080/livez
curl localhost:8080/readyz
curl localhost:8080/metrics
```

---

### 工程要点（为何“工业级”）

* **可观测性**：结构化日志 + `/metrics` 暴露 Prometheus 指标 + pprof。
* **鲁棒性**：全局速率限制、请求超时、中断/取消传播、错误分类。
* **可移植**：兼容 AWS S3 与 MinIO（PathStyle + 自定义 Endpoint）。
* **性能**：大文件自动多段上传（并发/分片可配），下载支持 Range。
* **运维友好**：健康检查、优雅退出、环境变量配置。

如果你希望我把它扩成**分层架构（service/repo/driver 包）**、加**OpenTelemetry trace**、**鉴权**、**跨桶复制**、**服务端加密策略**或**单元/集成测试**，我可以直接把版本 2 写出来。你更想先加哪块？
